{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import itertools\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "import pymorphy2\n",
    "import operator\n",
    "pd.set_option('max_colwidth', 999)\n",
    "max_cpu_count = multiprocessing.cpu_count()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Boris\n",
      "[nltk_data]     Feldman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_punctuation(row):\n",
    "    row['speech'] = row['speech'].translate(str.maketrans('', '', string.punctuation))\n",
    "    return row\n",
    "\n",
    "def drop_stop_words(row):\n",
    "    tokens = row['speech'].split()\n",
    "    dropped_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    row['speech'] = ' '.join(dropped_tokens)\n",
    "    return row\n",
    "\n",
    "def labels_transform(row):\n",
    "    if row['evaluation'] == '+':\n",
    "        row['evaluation'] = 1\n",
    "    elif row['evaluation'] == '-':\n",
    "        row['evaluation'] = 2\n",
    "    else:\n",
    "        row['evaluation'] = 3\n",
    "    return row\n",
    "\n",
    "def not_join(row):\n",
    "    row['speech'] = row['speech'].replace('не ', 'не')\n",
    "    row['speech'] = row['speech'].replace('Не ', 'Не')\n",
    "    return row\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def normalization(row):\n",
    "    tokens = row['speech'].split()\n",
    "    new_speech = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            new_speech.append(morph.parse(token)[0].normal_form)\n",
    "        except:\n",
    "            new_speech.append(token) \n",
    "    row['speech'] = ' '.join(new_speech)\n",
    "    return row\n",
    "    \n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('train.xlsx')[['speech', 'evaluation']]\n",
    "train = train.loc[(train['evaluation'] == '+') | (train['evaluation'] == '-') | (train['evaluation'] == '0')]\n",
    "\n",
    "test = pd.read_excel('test.xlsx')[['speech', 'evaluation']]\n",
    "test = test.loc[(test['evaluation'] == '+') | (test['evaluation'] == '-') | (test['evaluation'] == '0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train = train.apply(normalization, axis=1)\n",
    "normalized_test = test.apply(normalization, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat((train, test))\n",
    "# data_size = len(data)\n",
    "# split_coef = int(data_size * 0.8)\n",
    "# train = data.iloc[:split_coef]\n",
    "# test = data.iloc[split_coef:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, train, test, \n",
    "                 drop_punctuation_=True, \n",
    "                 drop_stop_words_=True,\n",
    "                 not_join_=True,\n",
    "                 data_model_type=None, \n",
    "                 classifier='Naive'):\n",
    "        self.train = train\n",
    "        self.test = test     \n",
    "        if drop_punctuation_:\n",
    "            self.train = self.train.apply(drop_punctuation, axis=1)\n",
    "            self.test = self.test.apply(drop_punctuation, axis=1) \n",
    "#         if normalization_:\n",
    "#             self.train = self.train.apply(normalization, axis=1)\n",
    "#             self.test = self.test.apply(normalization, axis=1)\n",
    "        if not_join_:\n",
    "            self.train = self.train.apply(not_join, axis=1)\n",
    "            self.test = self.test.apply(not_join, axis=1)\n",
    "        if drop_stop_words_:\n",
    "            self.train = self.train.apply(drop_stop_words, axis=1)        \n",
    "            self.test = self.test.apply(drop_stop_words, axis=1)\n",
    "        self.classifier = classifier\n",
    "        if data_model_type is None or classifier is None:\n",
    "            raise ValueError('None prameters are forbidden')       \n",
    "        self.data_model_type = data_model_type\n",
    "        self.data_model = None\n",
    "        self.model = None\n",
    "        \n",
    "    def data_model_processing(self):\n",
    "        self.train_y = np.array(self.train.apply(labels_transform, axis=1)['evaluation'])\n",
    "        self.test_y = np.array(self.test.apply(labels_transform, axis=1)['evaluation'])\n",
    "        if self.data_model_type in ['cv', 'tfidf', 'boolean']:\n",
    "            CV = CountVectorizer()\n",
    "            self.train_X = CV.fit_transform(self.train['speech'])\n",
    "            self.test_X = CV.transform(self.test['speech'])\n",
    "            if self.data_model_type == 'boolean':\n",
    "                self.train_X = csr_matrix(np.sign(self.train_X.toarray()))\n",
    "                self.test_X = csr_matrix(np.sign(self.test_X.toarray()))\n",
    "                \n",
    "            if self.data_model_type == 'tfidf':\n",
    "                tfidf = TfidfTransformer()\n",
    "                self.train_X = tfidf.fit_transform(self.train_X)\n",
    "                self.test_X = tfidf.transform(self.test_X)\n",
    "    def fit_model(self):\n",
    "        if self.classifier == 'Naive':\n",
    "            parameters = {\n",
    "                'alpha' : np.arange(0.1, 1.1, 0.1),\n",
    "                'fit_prior' : [True, False]\n",
    "            }\n",
    "            \n",
    "            self.nai_clf = MultinomialNB()\n",
    "            self.model = GridSearchCV(self.nai_clf, parameters, cv=2, verbose=0, n_jobs=max_cpu_count)\n",
    "            self.model.fit(self.train_X, self.train_y)\n",
    "\n",
    "        if self.classifier =='SVM':\n",
    "            parameters = {\n",
    "                'kernel' : ('linear', 'rbf'), \n",
    "                'C' : [1, 10],\n",
    "                'gamma' : [0.1, 0.4]\n",
    "            }\n",
    "            \n",
    "            self.svm_clf = SVC()\n",
    "            self.model = GridSearchCV(self.svm_clf, parameters, cv=2, verbose=0, n_jobs=max_cpu_count)\n",
    "            \n",
    "            self.model.fit(self.train_X, self.train_y)\n",
    "                  \n",
    "    def predict_model(self):\n",
    "        self.classification_results = {}\n",
    "        self.classification_results['prediction'] = self.model.predict(self.test_X)\n",
    "        if self.classifier == 'Naive':\n",
    "            self.classification_results['naive_best_model'] = self.model.best_params_\n",
    "        if self.classifier == 'SVM':\n",
    "            self.classification_results['svm_best_model'] = self.model.best_params_\n",
    "     \n",
    "    def prediction(self):\n",
    "        return self.classification_results['prediction']\n",
    "    \n",
    "    def classification_summary(self):\n",
    "        target_names = ['positive', 'negative', 'neutral']\n",
    "        d = classification_report(self.test_y, self.prediction(), target_names=target_names, output_dict=True)\n",
    "        s = classification_report(self.test_y, self.prediction(), target_names=target_names, output_dict=False)\n",
    "        return d, s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Executor:\n",
    "    def __init__(self):\n",
    "        self.drop_stop_words = [True, False]\n",
    "        self.not_join = [True, False]\n",
    "        self.data_model_type = ['cv', 'tfidf', 'boolean']\n",
    "        self.classifier = ['Naive', 'SVM']\n",
    "        self.normalization = [True, False]\n",
    "        self.product = []\n",
    "        for element in itertools.product(self.drop_stop_words, \n",
    "                                         self.data_model_type, \n",
    "                                         self.not_join, \n",
    "                                         self.classifier, \n",
    "                                         self.normalization):\n",
    "            self.product.append(element)\n",
    "        self.report = pd.DataFrame(columns=['parameters', 'accuracy', 'summary', 'model_details', 'dict_summary'])\n",
    "    def create_models(self):\n",
    "        print('Available model parameters:')\n",
    "        print('    drop_stop_words with values: {}'.format(self.drop_stop_words))\n",
    "        print('    not_join with values: {}'.format(self.not_join))\n",
    "        print('    data_model_type with values: {}'.format(self.data_model_type))\n",
    "        print('    classifier with values: {}'.format(self.classifier))\n",
    "        print('    normalization with values: {}'.format(self.normalization))\n",
    "        print('creating models...')\n",
    "        self.models = []\n",
    "        for param_set in tqdm_notebook(self.product):\n",
    "            if param_set[4]:\n",
    "                self.models.append(Model(normalized_train, normalized_test, \n",
    "                                     drop_punctuation_=True, \n",
    "                                     drop_stop_words_=param_set[0],\n",
    "                                     data_model_type=param_set[1],\n",
    "                                     not_join_=param_set[2],\n",
    "                                     classifier=param_set[3]))\n",
    "            else:\n",
    "                self.models.append(Model(train, test, \n",
    "                                     drop_punctuation_=True, \n",
    "                                     drop_stop_words_=param_set[0],\n",
    "                                     data_model_type=param_set[1],\n",
    "                                     not_join_=param_set[2],\n",
    "                                     classifier=param_set[3]))\n",
    "        print('{} models created'.format(len(self.product)))\n",
    "    def fit_models(self):\n",
    "        print('fitting models...')\n",
    "        for i, model in tqdm_notebook(enumerate(self.models)):\n",
    "            model.data_model_processing()\n",
    "            model.fit_model()\n",
    "            model.predict_model()\n",
    "            \n",
    "            acc = accuracy_score(model.prediction(), model.test_y)\n",
    "            to_insert = pd.Series(index=self.report.columns)\n",
    "            to_insert['parameters'] = self.product[i]\n",
    "            to_insert['accuracy'] = acc\n",
    "            to_insert['summary'] = model.classification_summary()[1]\n",
    "            to_insert['dict_summary'] = model.classification_summary()[0]\n",
    "            to_insert['model_details'] = '-'\n",
    "            if self.product[i][3] == 'Naive':\n",
    "                to_insert['model_details'] = model.classification_results['naive_best_model']\n",
    "            if self.product[i][3] == 'SVM':\n",
    "                to_insert['model_details'] = model.classification_results['svm_best_model']\n",
    "            self.report = self.report.append(to_insert, ignore_index=True)\n",
    "        self.report = self.report.sort_values(by=['accuracy'], ascending=False)\n",
    "        \n",
    "    def summary(self):\n",
    "        return self.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model parameters:\n",
      "    drop_stop_words with values: [True, False]\n",
      "    not_join with values: [True, False]\n",
      "    data_model_type with values: ['cv', 'tfidf', 'boolean']\n",
      "    classifier with values: ['Naive', 'SVM']\n",
      "    normalization with values: [True, False]\n",
      "creating models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0557f520a0b04fadab71dcd711a7530d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 models created\n",
      "fitting models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7b1316f2c5493db0b452eddb3827ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>summary</th>\n",
       "      <th>model_details</th>\n",
       "      <th>dict_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(False, cv, False, Naive, False)</td>\n",
       "      <td>0.624535</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.59      0.70      0.64      1448\\n    negative       0.66      0.80      0.72      1890\\n     neutral       0.59      0.27      0.37      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.60      4573\\n</td>\n",
       "      <td>{'alpha': 0.9, 'fit_prior': False}</td>\n",
       "      <td>{'positive': {'precision': 0.5929618768328446, 'recall': 0.6982044198895028, 'f1-score': 0.6412940057088488, 'support': 1448}, 'negative': {'precision': 0.6571180555555556, 'recall': 0.801058201058201, 'f1-score': 0.7219837863614688, 'support': 1890}, 'neutral': {'precision': 0.5868794326241135, 'recall': 0.2680161943319838, 'f1-score': 0.367982212340189, 'support': 1235}, 'micro avg': {'precision': 0.6245353159851301, 'recall': 0.6245353159851301, 'f1-score': 0.6245353159851301, 'support': 4573}, 'macro avg': {'precision': 0.6123197883375046, 'recall': 0.5890929384265625, 'f1-score': 0.5770866681368355, 'support': 4573}, 'weighted avg': {'precision': 0.6178346866268838, 'recall': 0.6245353159851301, 'f1-score': 0.6008312068072867, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(False, cv, False, Naive, True)</td>\n",
       "      <td>0.624535</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.59      0.70      0.64      1448\\n    negative       0.66      0.80      0.72      1890\\n     neutral       0.59      0.27      0.37      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.60      4573\\n</td>\n",
       "      <td>{'alpha': 0.9, 'fit_prior': False}</td>\n",
       "      <td>{'positive': {'precision': 0.5929618768328446, 'recall': 0.6982044198895028, 'f1-score': 0.6412940057088488, 'support': 1448}, 'negative': {'precision': 0.6571180555555556, 'recall': 0.801058201058201, 'f1-score': 0.7219837863614688, 'support': 1890}, 'neutral': {'precision': 0.5868794326241135, 'recall': 0.2680161943319838, 'f1-score': 0.367982212340189, 'support': 1235}, 'micro avg': {'precision': 0.6245353159851301, 'recall': 0.6245353159851301, 'f1-score': 0.6245353159851301, 'support': 4573}, 'macro avg': {'precision': 0.6123197883375046, 'recall': 0.5890929384265625, 'f1-score': 0.5770866681368355, 'support': 4573}, 'weighted avg': {'precision': 0.6178346866268838, 'recall': 0.6245353159851301, 'f1-score': 0.6008312068072867, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(False, boolean, False, Naive, False)</td>\n",
       "      <td>0.623005</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.58      0.71      0.64      1448\\n    negative       0.67      0.76      0.72      1890\\n     neutral       0.58      0.30      0.40      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.61      4573\\n</td>\n",
       "      <td>{'alpha': 0.7000000000000001, 'fit_prior': False}</td>\n",
       "      <td>{'positive': {'precision': 0.5759599332220368, 'recall': 0.7147790055248618, 'f1-score': 0.637904468412943, 'support': 1448}, 'negative': {'precision': 0.6743205248359887, 'recall': 0.7613756613756614, 'f1-score': 0.7152087475149104, 'support': 1890}, 'neutral': {'precision': 0.5841121495327103, 'recall': 0.30364372469635625, 'f1-score': 0.3995737879595098, 'support': 1235}, 'micro avg': {'precision': 0.6230045921714411, 'recall': 0.6230045921714411, 'f1-score': 0.6230045921714411, 'support': 4573}, 'macro avg': {'precision': 0.6114642025302452, 'recall': 0.5932661305322932, 'f1-score': 0.5842290012957877, 'support': 4573}, 'weighted avg': {'precision': 0.6188135315806745, 'recall': 0.6230045921714411, 'f1-score': 0.6054895760321707, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(False, boolean, False, Naive, True)</td>\n",
       "      <td>0.623005</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.58      0.71      0.64      1448\\n    negative       0.67      0.76      0.72      1890\\n     neutral       0.58      0.30      0.40      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.61      4573\\n</td>\n",
       "      <td>{'alpha': 0.7000000000000001, 'fit_prior': False}</td>\n",
       "      <td>{'positive': {'precision': 0.5759599332220368, 'recall': 0.7147790055248618, 'f1-score': 0.637904468412943, 'support': 1448}, 'negative': {'precision': 0.6743205248359887, 'recall': 0.7613756613756614, 'f1-score': 0.7152087475149104, 'support': 1890}, 'neutral': {'precision': 0.5841121495327103, 'recall': 0.30364372469635625, 'f1-score': 0.3995737879595098, 'support': 1235}, 'micro avg': {'precision': 0.6230045921714411, 'recall': 0.6230045921714411, 'f1-score': 0.6230045921714411, 'support': 4573}, 'macro avg': {'precision': 0.6114642025302452, 'recall': 0.5932661305322932, 'f1-score': 0.5842290012957877, 'support': 4573}, 'weighted avg': {'precision': 0.6188135315806745, 'recall': 0.6230045921714411, 'f1-score': 0.6054895760321707, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(False, boolean, True, Naive, False)</td>\n",
       "      <td>0.622786</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.59      0.72      0.65      1448\\n    negative       0.65      0.80      0.72      1890\\n     neutral       0.60      0.25      0.35      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.62      0.59      0.57      4573\\nweighted avg       0.62      0.62      0.60      4573\\n</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': False}</td>\n",
       "      <td>{'positive': {'precision': 0.5883352208380521, 'recall': 0.7175414364640884, 'f1-score': 0.6465463596764157, 'support': 1448}, 'negative': {'precision': 0.6531942633637549, 'recall': 0.7952380952380952, 'f1-score': 0.7172512526843237, 'support': 1890}, 'neutral': {'precision': 0.6047430830039525, 'recall': 0.24777327935222673, 'f1-score': 0.35152211372774267, 'support': 1235}, 'micro avg': {'precision': 0.622785917340914, 'recall': 0.622785917340914, 'f1-score': 0.622785917340914, 'support': 4573}, 'macro avg': {'precision': 0.6154241890685865, 'recall': 0.5868509370181368, 'f1-score': 0.571773242029494, 'support': 4573}, 'weighted avg': {'precision': 0.6195723299892582, 'recall': 0.622785917340914, 'f1-score': 0.5960931132382645, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(False, boolean, True, Naive, True)</td>\n",
       "      <td>0.622786</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.59      0.72      0.65      1448\\n    negative       0.65      0.80      0.72      1890\\n     neutral       0.60      0.25      0.35      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.62      0.59      0.57      4573\\nweighted avg       0.62      0.62      0.60      4573\\n</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': False}</td>\n",
       "      <td>{'positive': {'precision': 0.5883352208380521, 'recall': 0.7175414364640884, 'f1-score': 0.6465463596764157, 'support': 1448}, 'negative': {'precision': 0.6531942633637549, 'recall': 0.7952380952380952, 'f1-score': 0.7172512526843237, 'support': 1890}, 'neutral': {'precision': 0.6047430830039525, 'recall': 0.24777327935222673, 'f1-score': 0.35152211372774267, 'support': 1235}, 'micro avg': {'precision': 0.622785917340914, 'recall': 0.622785917340914, 'f1-score': 0.622785917340914, 'support': 4573}, 'macro avg': {'precision': 0.6154241890685865, 'recall': 0.5868509370181368, 'f1-score': 0.571773242029494, 'support': 4573}, 'weighted avg': {'precision': 0.6195723299892582, 'recall': 0.622785917340914, 'f1-score': 0.5960931132382645, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(False, tfidf, False, Naive, False)</td>\n",
       "      <td>0.621474</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.59      0.68      0.63      1448\\n    negative       0.65      0.80      0.71      1890\\n     neutral       0.60      0.28      0.38      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.60      4573\\n</td>\n",
       "      <td>{'alpha': 0.30000000000000004, 'fit_prior': False}</td>\n",
       "      <td>{'positive': {'precision': 0.5944477972238986, 'recall': 0.6802486187845304, 'f1-score': 0.6344605475040257, 'support': 1448}, 'negative': {'precision': 0.6452025586353944, 'recall': 0.8005291005291005, 'f1-score': 0.7145218417945691, 'support': 1890}, 'neutral': {'precision': 0.6024518388791593, 'recall': 0.2785425101214575, 'f1-score': 0.3809523809523809, 'support': 1235}, 'micro avg': {'precision': 0.621473868357752, 'recall': 0.621473868357752, 'f1-score': 0.621473868357752, 'support': 4573}, 'macro avg': {'precision': 0.6140340649128174, 'recall': 0.5864400764783628, 'f1-score': 0.5766449234169919, 'support': 4573}, 'weighted avg': {'precision': 0.6175861069794145, 'recall': 0.621473868357752, 'f1-score': 0.5990862331628591, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(False, tfidf, False, Naive, True)</td>\n",
       "      <td>0.621474</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.59      0.68      0.63      1448\\n    negative       0.65      0.80      0.71      1890\\n     neutral       0.60      0.28      0.38      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.60      4573\\n</td>\n",
       "      <td>{'alpha': 0.30000000000000004, 'fit_prior': False}</td>\n",
       "      <td>{'positive': {'precision': 0.5944477972238986, 'recall': 0.6802486187845304, 'f1-score': 0.6344605475040257, 'support': 1448}, 'negative': {'precision': 0.6452025586353944, 'recall': 0.8005291005291005, 'f1-score': 0.7145218417945691, 'support': 1890}, 'neutral': {'precision': 0.6024518388791593, 'recall': 0.2785425101214575, 'f1-score': 0.3809523809523809, 'support': 1235}, 'micro avg': {'precision': 0.621473868357752, 'recall': 0.621473868357752, 'f1-score': 0.621473868357752, 'support': 4573}, 'macro avg': {'precision': 0.6140340649128174, 'recall': 0.5864400764783628, 'f1-score': 0.5766449234169919, 'support': 4573}, 'weighted avg': {'precision': 0.6175861069794145, 'recall': 0.621473868357752, 'f1-score': 0.5990862331628591, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(False, cv, True, Naive, True)</td>\n",
       "      <td>0.619943</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.59      0.71      0.64      1448\\n    negative       0.65      0.78      0.71      1890\\n     neutral       0.58      0.27      0.37      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.57      4573\\nweighted avg       0.61      0.62      0.60      4573\\n</td>\n",
       "      <td>{'alpha': 0.7000000000000001, 'fit_prior': True}</td>\n",
       "      <td>{'positive': {'precision': 0.5876940770557791, 'recall': 0.7058011049723757, 'f1-score': 0.6413555067461563, 'support': 1448}, 'negative': {'precision': 0.6544571932921448, 'recall': 0.7846560846560846, 'f1-score': 0.7136669874879693, 'support': 1890}, 'neutral': {'precision': 0.5809859154929577, 'recall': 0.26720647773279355, 'f1-score': 0.36605657237936773, 'support': 1235}, 'micro avg': {'precision': 0.619943144544063, 'recall': 0.619943144544063, 'f1-score': 0.619943144544063, 'support': 4573}, 'macro avg': {'precision': 0.6077123952802939, 'recall': 0.5858878891204179, 'f1-score': 0.5736930222044978, 'support': 4573}, 'weighted avg': {'precision': 0.6134753388438059, 'recall': 0.619943144544063, 'f1-score': 0.5968933406974011, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(False, cv, True, Naive, False)</td>\n",
       "      <td>0.619943</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.59      0.71      0.64      1448\\n    negative       0.65      0.78      0.71      1890\\n     neutral       0.58      0.27      0.37      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.57      4573\\nweighted avg       0.61      0.62      0.60      4573\\n</td>\n",
       "      <td>{'alpha': 0.7000000000000001, 'fit_prior': True}</td>\n",
       "      <td>{'positive': {'precision': 0.5876940770557791, 'recall': 0.7058011049723757, 'f1-score': 0.6413555067461563, 'support': 1448}, 'negative': {'precision': 0.6544571932921448, 'recall': 0.7846560846560846, 'f1-score': 0.7136669874879693, 'support': 1890}, 'neutral': {'precision': 0.5809859154929577, 'recall': 0.26720647773279355, 'f1-score': 0.36605657237936773, 'support': 1235}, 'micro avg': {'precision': 0.619943144544063, 'recall': 0.619943144544063, 'f1-score': 0.619943144544063, 'support': 4573}, 'macro avg': {'precision': 0.6077123952802939, 'recall': 0.5858878891204179, 'f1-score': 0.5736930222044978, 'support': 4573}, 'weighted avg': {'precision': 0.6134753388438059, 'recall': 0.619943144544063, 'f1-score': 0.5968933406974011, 'support': 4573}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               parameters  accuracy  \\\n",
       "29       (False, cv, False, Naive, False)  0.624535   \n",
       "28        (False, cv, False, Naive, True)  0.624535   \n",
       "45  (False, boolean, False, Naive, False)  0.623005   \n",
       "44   (False, boolean, False, Naive, True)  0.623005   \n",
       "41   (False, boolean, True, Naive, False)  0.622786   \n",
       "40    (False, boolean, True, Naive, True)  0.622786   \n",
       "37    (False, tfidf, False, Naive, False)  0.621474   \n",
       "36     (False, tfidf, False, Naive, True)  0.621474   \n",
       "24         (False, cv, True, Naive, True)  0.619943   \n",
       "25        (False, cv, True, Naive, False)  0.619943   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                  summary  \\\n",
       "29                precision    recall  f1-score   support\\n\\n    positive       0.59      0.70      0.64      1448\\n    negative       0.66      0.80      0.72      1890\\n     neutral       0.59      0.27      0.37      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.60      4573\\n   \n",
       "28                precision    recall  f1-score   support\\n\\n    positive       0.59      0.70      0.64      1448\\n    negative       0.66      0.80      0.72      1890\\n     neutral       0.59      0.27      0.37      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.60      4573\\n   \n",
       "45                precision    recall  f1-score   support\\n\\n    positive       0.58      0.71      0.64      1448\\n    negative       0.67      0.76      0.72      1890\\n     neutral       0.58      0.30      0.40      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.61      4573\\n   \n",
       "44                precision    recall  f1-score   support\\n\\n    positive       0.58      0.71      0.64      1448\\n    negative       0.67      0.76      0.72      1890\\n     neutral       0.58      0.30      0.40      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.61      4573\\n   \n",
       "41                precision    recall  f1-score   support\\n\\n    positive       0.59      0.72      0.65      1448\\n    negative       0.65      0.80      0.72      1890\\n     neutral       0.60      0.25      0.35      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.62      0.59      0.57      4573\\nweighted avg       0.62      0.62      0.60      4573\\n   \n",
       "40                precision    recall  f1-score   support\\n\\n    positive       0.59      0.72      0.65      1448\\n    negative       0.65      0.80      0.72      1890\\n     neutral       0.60      0.25      0.35      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.62      0.59      0.57      4573\\nweighted avg       0.62      0.62      0.60      4573\\n   \n",
       "37                precision    recall  f1-score   support\\n\\n    positive       0.59      0.68      0.63      1448\\n    negative       0.65      0.80      0.71      1890\\n     neutral       0.60      0.28      0.38      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.60      4573\\n   \n",
       "36                precision    recall  f1-score   support\\n\\n    positive       0.59      0.68      0.63      1448\\n    negative       0.65      0.80      0.71      1890\\n     neutral       0.60      0.28      0.38      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.58      4573\\nweighted avg       0.62      0.62      0.60      4573\\n   \n",
       "24                precision    recall  f1-score   support\\n\\n    positive       0.59      0.71      0.64      1448\\n    negative       0.65      0.78      0.71      1890\\n     neutral       0.58      0.27      0.37      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.57      4573\\nweighted avg       0.61      0.62      0.60      4573\\n   \n",
       "25                precision    recall  f1-score   support\\n\\n    positive       0.59      0.71      0.64      1448\\n    negative       0.65      0.78      0.71      1890\\n     neutral       0.58      0.27      0.37      1235\\n\\n   micro avg       0.62      0.62      0.62      4573\\n   macro avg       0.61      0.59      0.57      4573\\nweighted avg       0.61      0.62      0.60      4573\\n   \n",
       "\n",
       "                                         model_details  \\\n",
       "29                  {'alpha': 0.9, 'fit_prior': False}   \n",
       "28                  {'alpha': 0.9, 'fit_prior': False}   \n",
       "45   {'alpha': 0.7000000000000001, 'fit_prior': False}   \n",
       "44   {'alpha': 0.7000000000000001, 'fit_prior': False}   \n",
       "41                  {'alpha': 1.0, 'fit_prior': False}   \n",
       "40                  {'alpha': 1.0, 'fit_prior': False}   \n",
       "37  {'alpha': 0.30000000000000004, 'fit_prior': False}   \n",
       "36  {'alpha': 0.30000000000000004, 'fit_prior': False}   \n",
       "24    {'alpha': 0.7000000000000001, 'fit_prior': True}   \n",
       "25    {'alpha': 0.7000000000000001, 'fit_prior': True}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 dict_summary  \n",
       "29    {'positive': {'precision': 0.5929618768328446, 'recall': 0.6982044198895028, 'f1-score': 0.6412940057088488, 'support': 1448}, 'negative': {'precision': 0.6571180555555556, 'recall': 0.801058201058201, 'f1-score': 0.7219837863614688, 'support': 1890}, 'neutral': {'precision': 0.5868794326241135, 'recall': 0.2680161943319838, 'f1-score': 0.367982212340189, 'support': 1235}, 'micro avg': {'precision': 0.6245353159851301, 'recall': 0.6245353159851301, 'f1-score': 0.6245353159851301, 'support': 4573}, 'macro avg': {'precision': 0.6123197883375046, 'recall': 0.5890929384265625, 'f1-score': 0.5770866681368355, 'support': 4573}, 'weighted avg': {'precision': 0.6178346866268838, 'recall': 0.6245353159851301, 'f1-score': 0.6008312068072867, 'support': 4573}}  \n",
       "28    {'positive': {'precision': 0.5929618768328446, 'recall': 0.6982044198895028, 'f1-score': 0.6412940057088488, 'support': 1448}, 'negative': {'precision': 0.6571180555555556, 'recall': 0.801058201058201, 'f1-score': 0.7219837863614688, 'support': 1890}, 'neutral': {'precision': 0.5868794326241135, 'recall': 0.2680161943319838, 'f1-score': 0.367982212340189, 'support': 1235}, 'micro avg': {'precision': 0.6245353159851301, 'recall': 0.6245353159851301, 'f1-score': 0.6245353159851301, 'support': 4573}, 'macro avg': {'precision': 0.6123197883375046, 'recall': 0.5890929384265625, 'f1-score': 0.5770866681368355, 'support': 4573}, 'weighted avg': {'precision': 0.6178346866268838, 'recall': 0.6245353159851301, 'f1-score': 0.6008312068072867, 'support': 4573}}  \n",
       "45  {'positive': {'precision': 0.5759599332220368, 'recall': 0.7147790055248618, 'f1-score': 0.637904468412943, 'support': 1448}, 'negative': {'precision': 0.6743205248359887, 'recall': 0.7613756613756614, 'f1-score': 0.7152087475149104, 'support': 1890}, 'neutral': {'precision': 0.5841121495327103, 'recall': 0.30364372469635625, 'f1-score': 0.3995737879595098, 'support': 1235}, 'micro avg': {'precision': 0.6230045921714411, 'recall': 0.6230045921714411, 'f1-score': 0.6230045921714411, 'support': 4573}, 'macro avg': {'precision': 0.6114642025302452, 'recall': 0.5932661305322932, 'f1-score': 0.5842290012957877, 'support': 4573}, 'weighted avg': {'precision': 0.6188135315806745, 'recall': 0.6230045921714411, 'f1-score': 0.6054895760321707, 'support': 4573}}  \n",
       "44  {'positive': {'precision': 0.5759599332220368, 'recall': 0.7147790055248618, 'f1-score': 0.637904468412943, 'support': 1448}, 'negative': {'precision': 0.6743205248359887, 'recall': 0.7613756613756614, 'f1-score': 0.7152087475149104, 'support': 1890}, 'neutral': {'precision': 0.5841121495327103, 'recall': 0.30364372469635625, 'f1-score': 0.3995737879595098, 'support': 1235}, 'micro avg': {'precision': 0.6230045921714411, 'recall': 0.6230045921714411, 'f1-score': 0.6230045921714411, 'support': 4573}, 'macro avg': {'precision': 0.6114642025302452, 'recall': 0.5932661305322932, 'f1-score': 0.5842290012957877, 'support': 4573}, 'weighted avg': {'precision': 0.6188135315806745, 'recall': 0.6230045921714411, 'f1-score': 0.6054895760321707, 'support': 4573}}  \n",
       "41     {'positive': {'precision': 0.5883352208380521, 'recall': 0.7175414364640884, 'f1-score': 0.6465463596764157, 'support': 1448}, 'negative': {'precision': 0.6531942633637549, 'recall': 0.7952380952380952, 'f1-score': 0.7172512526843237, 'support': 1890}, 'neutral': {'precision': 0.6047430830039525, 'recall': 0.24777327935222673, 'f1-score': 0.35152211372774267, 'support': 1235}, 'micro avg': {'precision': 0.622785917340914, 'recall': 0.622785917340914, 'f1-score': 0.622785917340914, 'support': 4573}, 'macro avg': {'precision': 0.6154241890685865, 'recall': 0.5868509370181368, 'f1-score': 0.571773242029494, 'support': 4573}, 'weighted avg': {'precision': 0.6195723299892582, 'recall': 0.622785917340914, 'f1-score': 0.5960931132382645, 'support': 4573}}  \n",
       "40     {'positive': {'precision': 0.5883352208380521, 'recall': 0.7175414364640884, 'f1-score': 0.6465463596764157, 'support': 1448}, 'negative': {'precision': 0.6531942633637549, 'recall': 0.7952380952380952, 'f1-score': 0.7172512526843237, 'support': 1890}, 'neutral': {'precision': 0.6047430830039525, 'recall': 0.24777327935222673, 'f1-score': 0.35152211372774267, 'support': 1235}, 'micro avg': {'precision': 0.622785917340914, 'recall': 0.622785917340914, 'f1-score': 0.622785917340914, 'support': 4573}, 'macro avg': {'precision': 0.6154241890685865, 'recall': 0.5868509370181368, 'f1-score': 0.571773242029494, 'support': 4573}, 'weighted avg': {'precision': 0.6195723299892582, 'recall': 0.622785917340914, 'f1-score': 0.5960931132382645, 'support': 4573}}  \n",
       "37      {'positive': {'precision': 0.5944477972238986, 'recall': 0.6802486187845304, 'f1-score': 0.6344605475040257, 'support': 1448}, 'negative': {'precision': 0.6452025586353944, 'recall': 0.8005291005291005, 'f1-score': 0.7145218417945691, 'support': 1890}, 'neutral': {'precision': 0.6024518388791593, 'recall': 0.2785425101214575, 'f1-score': 0.3809523809523809, 'support': 1235}, 'micro avg': {'precision': 0.621473868357752, 'recall': 0.621473868357752, 'f1-score': 0.621473868357752, 'support': 4573}, 'macro avg': {'precision': 0.6140340649128174, 'recall': 0.5864400764783628, 'f1-score': 0.5766449234169919, 'support': 4573}, 'weighted avg': {'precision': 0.6175861069794145, 'recall': 0.621473868357752, 'f1-score': 0.5990862331628591, 'support': 4573}}  \n",
       "36      {'positive': {'precision': 0.5944477972238986, 'recall': 0.6802486187845304, 'f1-score': 0.6344605475040257, 'support': 1448}, 'negative': {'precision': 0.6452025586353944, 'recall': 0.8005291005291005, 'f1-score': 0.7145218417945691, 'support': 1890}, 'neutral': {'precision': 0.6024518388791593, 'recall': 0.2785425101214575, 'f1-score': 0.3809523809523809, 'support': 1235}, 'micro avg': {'precision': 0.621473868357752, 'recall': 0.621473868357752, 'f1-score': 0.621473868357752, 'support': 4573}, 'macro avg': {'precision': 0.6140340649128174, 'recall': 0.5864400764783628, 'f1-score': 0.5766449234169919, 'support': 4573}, 'weighted avg': {'precision': 0.6175861069794145, 'recall': 0.621473868357752, 'f1-score': 0.5990862331628591, 'support': 4573}}  \n",
       "24    {'positive': {'precision': 0.5876940770557791, 'recall': 0.7058011049723757, 'f1-score': 0.6413555067461563, 'support': 1448}, 'negative': {'precision': 0.6544571932921448, 'recall': 0.7846560846560846, 'f1-score': 0.7136669874879693, 'support': 1890}, 'neutral': {'precision': 0.5809859154929577, 'recall': 0.26720647773279355, 'f1-score': 0.36605657237936773, 'support': 1235}, 'micro avg': {'precision': 0.619943144544063, 'recall': 0.619943144544063, 'f1-score': 0.619943144544063, 'support': 4573}, 'macro avg': {'precision': 0.6077123952802939, 'recall': 0.5858878891204179, 'f1-score': 0.5736930222044978, 'support': 4573}, 'weighted avg': {'precision': 0.6134753388438059, 'recall': 0.619943144544063, 'f1-score': 0.5968933406974011, 'support': 4573}}  \n",
       "25    {'positive': {'precision': 0.5876940770557791, 'recall': 0.7058011049723757, 'f1-score': 0.6413555067461563, 'support': 1448}, 'negative': {'precision': 0.6544571932921448, 'recall': 0.7846560846560846, 'f1-score': 0.7136669874879693, 'support': 1890}, 'neutral': {'precision': 0.5809859154929577, 'recall': 0.26720647773279355, 'f1-score': 0.36605657237936773, 'support': 1235}, 'micro avg': {'precision': 0.619943144544063, 'recall': 0.619943144544063, 'f1-score': 0.619943144544063, 'support': 4573}, 'macro avg': {'precision': 0.6077123952802939, 'recall': 0.5858878891204179, 'f1-score': 0.5736930222044978, 'support': 4573}, 'weighted avg': {'precision': 0.6134753388438059, 'recall': 0.619943144544063, 'f1-score': 0.5968933406974011, 'support': 4573}}  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = Executor()\n",
    "e.create_models()\n",
    "e.fit_models()\n",
    "e.summary().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((False, 'cv', False, 'Naive', False), 0.6245353159851301),\n",
       " ((False, 'cv', False, 'Naive', True), 0.6245353159851301),\n",
       " ((False, 'boolean', False, 'Naive', False), 0.6230045921714411),\n",
       " ((False, 'boolean', False, 'Naive', True), 0.6230045921714411),\n",
       " ((False, 'boolean', True, 'Naive', False), 0.622785917340914),\n",
       " ((False, 'boolean', True, 'Naive', True), 0.622785917340914),\n",
       " ((False, 'tfidf', False, 'Naive', False), 0.621473868357752),\n",
       " ((False, 'tfidf', False, 'Naive', True), 0.621473868357752),\n",
       " ((False, 'cv', True, 'Naive', True), 0.619943144544063),\n",
       " ((False, 'cv', True, 'Naive', False), 0.619943144544063),\n",
       " ((False, 'tfidf', True, 'Naive', False), 0.618412420730374),\n",
       " ((False, 'tfidf', True, 'Naive', True), 0.618412420730374),\n",
       " ((True, 'boolean', True, 'Naive', True), 0.6179750710693199),\n",
       " ((True, 'boolean', True, 'Naive', False), 0.6179750710693199),\n",
       " ((True, 'cv', True, 'Naive', False), 0.6160069975945769),\n",
       " ((True, 'cv', True, 'Naive', True), 0.6160069975945769),\n",
       " ((True, 'cv', False, 'Naive', True), 0.6138202492893068),\n",
       " ((True, 'cv', False, 'Naive', False), 0.6138202492893068),\n",
       " ((True, 'boolean', False, 'Naive', True), 0.6133828996282528),\n",
       " ((True, 'boolean', False, 'Naive', False), 0.6133828996282528),\n",
       " ((True, 'tfidf', True, 'Naive', False), 0.6094467526787667),\n",
       " ((True, 'tfidf', True, 'Naive', True), 0.6094467526787667),\n",
       " ((False, 'tfidf', False, 'SVM', False), 0.6074786792040237),\n",
       " ((False, 'tfidf', False, 'SVM', True), 0.6074786792040237),\n",
       " ((True, 'tfidf', False, 'Naive', False), 0.6063853050513885),\n",
       " ((True, 'tfidf', False, 'Naive', True), 0.6063853050513885),\n",
       " ((False, 'tfidf', True, 'SVM', False), 0.6022304832713755),\n",
       " ((False, 'tfidf', True, 'SVM', True), 0.6022304832713755),\n",
       " ((True, 'tfidf', True, 'SVM', False), 0.6002624097966324),\n",
       " ((True, 'tfidf', True, 'SVM', True), 0.6002624097966324),\n",
       " ((True, 'tfidf', False, 'SVM', True), 0.5956702383555653),\n",
       " ((True, 'tfidf', False, 'SVM', False), 0.5956702383555653),\n",
       " ((False, 'boolean', False, 'SVM', True), 0.5713973321670676),\n",
       " ((False, 'boolean', False, 'SVM', False), 0.5713973321670676),\n",
       " ((True, 'cv', True, 'SVM', False), 0.5700852831839055),\n",
       " ((True, 'cv', True, 'SVM', True), 0.5700852831839055),\n",
       " ((True, 'boolean', True, 'SVM', False), 0.5696479335228515),\n",
       " ((True, 'boolean', True, 'SVM', True), 0.5696479335228515),\n",
       " ((False, 'cv', False, 'SVM', False), 0.5689919090312705),\n",
       " ((False, 'cv', False, 'SVM', True), 0.5689919090312705),\n",
       " ((False, 'cv', True, 'SVM', False), 0.5678985348786355),\n",
       " ((False, 'cv', True, 'SVM', True), 0.5678985348786355),\n",
       " ((False, 'boolean', True, 'SVM', True), 0.5641810627596764),\n",
       " ((False, 'boolean', True, 'SVM', False), 0.5641810627596764),\n",
       " ((True, 'cv', False, 'SVM', False), 0.5609009403017713),\n",
       " ((True, 'cv', False, 'SVM', True), 0.5609009403017713),\n",
       " ((True, 'boolean', False, 'SVM', False), 0.5589328668270283),\n",
       " ((True, 'boolean', False, 'SVM', True), 0.5589328668270283)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_sort = {}\n",
    "for row in e.summary().values:\n",
    "    f1_sort[row[0]] =  row[4]['micro avg']['f1-score']\n",
    "f1_sort = sorted(f1_sort.items(), key=operator.itemgetter(1), reverse=True)\n",
    "f1_sort[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.59      0.70      0.64      1448\n",
      "    negative       0.66      0.80      0.72      1890\n",
      "     neutral       0.59      0.27      0.37      1235\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      4573\n",
      "   macro avg       0.61      0.59      0.58      4573\n",
      "weighted avg       0.62      0.62      0.60      4573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(e.summary().iloc[0]['summary'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
