{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import itertools\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "pd.set_option('max_colwidth', 999)\n",
    "max_cpu_count = multiprocessing.cpu_count()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Владимир\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_punctuation(row):\n",
    "    row['speech'] = row['speech'].translate(str.maketrans('', '', string.punctuation))\n",
    "    return row\n",
    "\n",
    "def drop_stop_words(row):\n",
    "    tokens = row['speech'].split()\n",
    "    dropped_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    row['speech'] = ' '.join(dropped_tokens)\n",
    "    return row\n",
    "\n",
    "def labels_transform(row):\n",
    "    if row['evaluation'] == '+':\n",
    "        row['evaluation'] = 1\n",
    "    elif row['evaluation'] == '-':\n",
    "        row['evaluation'] = 2\n",
    "    else:\n",
    "        row['evaluation'] = 3\n",
    "    return row\n",
    "\n",
    "def not_join(row):\n",
    "    row['speech'] = row['speech'].replace('не ', 'не')\n",
    "    row['speech'] = row['speech'].replace('Не ', 'Не')\n",
    "    return row\n",
    "    \n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('train.xlsx')[['speech', 'evaluation']]\n",
    "train = train.loc[(train['evaluation'] == '+') | (train['evaluation'] == '-') | (train['evaluation'] == '0')]\n",
    "\n",
    "test = pd.read_excel('test.xlsx')[['speech', 'evaluation']]\n",
    "test = test.loc[(test['evaluation'] == '+') | (test['evaluation'] == '-') | (test['evaluation'] == '0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((train, test))\n",
    "data_size = len(data)\n",
    "split_coef = int(data_size * 0.8)\n",
    "train = data.iloc[:split_coef]\n",
    "test = data.iloc[split_coef:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, train, test, \n",
    "                 drop_punctuation_=True, \n",
    "                 drop_stop_words_=True,\n",
    "                 not_join_=True,\n",
    "                 data_model_type=None, \n",
    "                 classifier='Naive'):\n",
    "        self.train = train\n",
    "        self.test = test     \n",
    "        if drop_punctuation_:\n",
    "            self.train = self.train.apply(drop_punctuation, axis=1)\n",
    "            self.test = self.test.apply(drop_punctuation, axis=1)       \n",
    "        if drop_stop_words_:\n",
    "            self.train = self.train.apply(drop_stop_words, axis=1)        \n",
    "            self.test = self.test.apply(drop_stop_words, axis=1)  \n",
    "        if not_join_:\n",
    "            self.train = self.train.apply(not_join, axis=1)\n",
    "            self.test = self.test.apply(not_join, axis=1)\n",
    "        self.classifier = classifier\n",
    "        if data_model_type is None or classifier is None:\n",
    "            raise ValueError('None prameters are forbidden')       \n",
    "        self.data_model_type = data_model_type\n",
    "        self.data_model = None\n",
    "        self.model = None\n",
    "        \n",
    "    def data_model_processing(self):\n",
    "        self.train_y = np.array(self.train.apply(labels_transform, axis=1)['evaluation'])\n",
    "        self.test_y = np.array(self.test.apply(labels_transform, axis=1)['evaluation'])\n",
    "        if self.data_model_type in ['cv', 'tfidf', 'boolean']:\n",
    "            CV = CountVectorizer()\n",
    "            self.train_X = CV.fit_transform(self.train['speech'])\n",
    "            self.test_X = CV.transform(self.test['speech'])\n",
    "            if self.data_model_type == 'boolean':\n",
    "                self.train_X = csr_matrix(np.sign(self.train_X.toarray()))\n",
    "                self.test_X = csr_matrix(np.sign(self.test_X.toarray()))\n",
    "                \n",
    "            if self.data_model_type == 'tfidf':\n",
    "                tfidf = TfidfTransformer()\n",
    "                self.train_X = tfidf.fit_transform(self.train_X)\n",
    "                self.test_X = tfidf.transform(self.test_X)\n",
    "    def fit_model(self):\n",
    "        if self.classifier == 'Naive':\n",
    "            self.model = MultinomialNB()\n",
    "            self.model.fit(self.train_X, self.train_y)\n",
    "\n",
    "        if self.classifier =='SVM':\n",
    "#             parameters = {\n",
    "#                 'kernel' : ('linear', 'rbf', 'poly'), \n",
    "#                 'C' : [1, 10],\n",
    "#                 'gamma' : np.arange(0.1, 1, 0.1),\n",
    "#                 'degree' : [2, 3, 4]\n",
    "#             }\n",
    "            parameters = {\n",
    "                'kernel' : ('linear', 'rbf'), \n",
    "                'C' : [1, 10],\n",
    "                'gamma' : [0.1, 0.4]\n",
    "            }\n",
    "            \n",
    "            self.svm_clf = SVC()\n",
    "            self.model = GridSearchCV(self.svm_clf, parameters, cv=None, verbose=1, n_jobs=max_cpu_count)\n",
    "            \n",
    "            self.model.fit(self.train_X, self.train_y)\n",
    "                  \n",
    "    def predict_model(self):\n",
    "        self.classification_results = {}\n",
    "        self.classification_results['prediction'] = self.model.predict(self.test_X)\n",
    "        if self.classifier == 'SVM':\n",
    "            self.classification_results['svm_best_model'] = self.model.best_params_\n",
    "     \n",
    "    def prediction(self):\n",
    "        return self.classification_results['prediction']\n",
    "    \n",
    "    def classification_summary(self):\n",
    "        target_names = ['positive', 'negative', 'neutral']\n",
    "        d = classification_report(self.test_y, self.prediction(), target_names=target_names, output_dict=True)\n",
    "        s = classification_report(self.test_y, self.prediction(), target_names=target_names, output_dict=False)\n",
    "        return d, s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Executor:\n",
    "    def __init__(self):\n",
    "        self.drop_stop_words = [True, False]\n",
    "        self.not_join = [True, False]\n",
    "        self.data_model_type = ['cv', 'tfidf', 'boolean']\n",
    "        self.classifier = ['Naive', 'SVM']\n",
    "        self.product = []\n",
    "        for element in itertools.product(self.drop_stop_words, self.data_model_type, self.not_join, self.classifier):\n",
    "            self.product.append(element)\n",
    "        self.report = pd.DataFrame(columns=['parameters', 'accuracy', 'summary', 'model_details'])\n",
    "    def create_models(self):\n",
    "        print('Available model parameters:')\n",
    "        print('    drop_stop_words with values: {}'.format(self.drop_stop_words))\n",
    "        print('    not_join with values: {}'.format(self.not_join))\n",
    "        print('    data_model_type with values: {}'.format(self.data_model_type))\n",
    "        print('    classifier with values: {}'.format(self.classifier))\n",
    "        print('creating models...')\n",
    "        self.models = []\n",
    "        for param_set in tqdm_notebook(self.product):\n",
    "            self.models.append(Model(train, test, \n",
    "                                     drop_punctuation_=True, \n",
    "                                     drop_stop_words_=param_set[0],\n",
    "                                     data_model_type=param_set[1],\n",
    "                                     not_join_=param_set[2],\n",
    "                                     classifier=param_set[3]))\n",
    "        print('{} models created'.format(len(self.product)))\n",
    "    def fit_models(self):\n",
    "        print('fitting models...')\n",
    "        for i, model in tqdm_notebook(enumerate(self.models)):\n",
    "            model.data_model_processing()\n",
    "            model.fit_model()\n",
    "            model.predict_model()\n",
    "            \n",
    "            acc = accuracy_score(model.prediction(), model.test_y)\n",
    "            to_insert = pd.Series(index=self.report.columns)\n",
    "            to_insert['parameters'] = self.product[i]\n",
    "            to_insert['accuracy'] = acc\n",
    "            to_insert['summary'] = model.classification_summary()[1]\n",
    "            to_insert['model_details'] = '-'\n",
    "            \n",
    "            if self.product[i][3] == 'SVM':\n",
    "                to_insert['model_details'] = model.classification_results['svm_best_model']\n",
    "            self.report = self.report.append(to_insert, ignore_index=True)\n",
    "        self.report = self.report.sort_values(by=['accuracy'], ascending=False)\n",
    "        \n",
    "    def summary(self):\n",
    "        return self.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model parameters:\n",
      "    drop_stop_words with values: [True, False]\n",
      "    not_join with values: [True, False]\n",
      "    data_model_type with values: ['cv', 'tfidf', 'boolean']\n",
      "    classifier with values: ['Naive', 'SVM']\n",
      "creating models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d32b4e71054335aba5fd4587215626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "24 models created\n",
      "fitting models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e192bc20cd462fb95164e736c9eabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   33.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   33.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   32.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   33.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   33.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   33.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   40.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   41.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   39.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   40.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   40.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  24 out of  24 | elapsed:   40.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>summary</th>\n",
       "      <th>model_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(False, cv, False, Naive)</td>\n",
       "      <td>0.643447</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.56      0.73      0.63       475\\n    negative       0.71      0.82      0.76       766\\n     neutral       0.62      0.26      0.36       453\\n\\n   micro avg       0.64      0.64      0.64      1694\\n   macro avg       0.63      0.60      0.59      1694\\nweighted avg       0.64      0.64      0.62      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(False, cv, True, Naive)</td>\n",
       "      <td>0.637544</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.54      0.73      0.62       475\\n    negative       0.72      0.80      0.76       766\\n     neutral       0.60      0.26      0.36       453\\n\\n   micro avg       0.64      0.64      0.64      1694\\n   macro avg       0.62      0.60      0.58      1694\\nweighted avg       0.64      0.64      0.61      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(False, boolean, False, Naive)</td>\n",
       "      <td>0.635773</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.54      0.73      0.62       475\\n    negative       0.71      0.80      0.75       766\\n     neutral       0.63      0.25      0.35       453\\n\\n   micro avg       0.64      0.64      0.64      1694\\n   macro avg       0.62      0.60      0.58      1694\\nweighted avg       0.64      0.64      0.61      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(False, boolean, True, Naive)</td>\n",
       "      <td>0.631641</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.54      0.73      0.62       475\\n    negative       0.71      0.80      0.75       766\\n     neutral       0.61      0.24      0.34       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.62      0.59      0.57      1694\\nweighted avg       0.63      0.63      0.61      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(False, tfidf, False, SVM)</td>\n",
       "      <td>0.629280</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.56      0.68      0.61       475\\n    negative       0.71      0.78      0.75       766\\n     neutral       0.53      0.31      0.39       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.60      0.59      0.58      1694\\nweighted avg       0.62      0.63      0.61      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(False, tfidf, True, SVM)</td>\n",
       "      <td>0.626919</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.55      0.68      0.61       475\\n    negative       0.71      0.78      0.74       766\\n     neutral       0.53      0.31      0.39       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.60      0.59      0.58      1694\\nweighted avg       0.62      0.63      0.61      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(True, boolean, False, Naive)</td>\n",
       "      <td>0.626328</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.54      0.75      0.63       475\\n    negative       0.72      0.75      0.73       766\\n     neutral       0.56      0.28      0.37       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.61      0.60      0.58      1694\\nweighted avg       0.63      0.63      0.61      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(True, cv, False, Naive)</td>\n",
       "      <td>0.626328</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.54      0.75      0.63       475\\n    negative       0.72      0.75      0.73       766\\n     neutral       0.54      0.28      0.37       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.60      0.60      0.58      1694\\nweighted avg       0.62      0.63      0.61      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(True, boolean, True, Naive)</td>\n",
       "      <td>0.623967</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.53      0.74      0.62       475\\n    negative       0.72      0.76      0.74       766\\n     neutral       0.56      0.28      0.37       453\\n\\n   micro avg       0.62      0.62      0.62      1694\\n   macro avg       0.60      0.59      0.58      1694\\nweighted avg       0.62      0.62      0.61      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(True, cv, True, Naive)</td>\n",
       "      <td>0.620425</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.54      0.74      0.63       475\\n    negative       0.71      0.75      0.73       766\\n     neutral       0.53      0.27      0.35       453\\n\\n   micro avg       0.62      0.62      0.62      1694\\n   macro avg       0.59      0.59      0.57      1694\\nweighted avg       0.61      0.62      0.60      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(True, tfidf, False, SVM)</td>\n",
       "      <td>0.619835</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.55      0.67      0.60       475\\n    negative       0.71      0.76      0.73       766\\n     neutral       0.51      0.34      0.41       453\\n\\n   micro avg       0.62      0.62      0.62      1694\\n   macro avg       0.59      0.59      0.58      1694\\nweighted avg       0.61      0.62      0.61      1694\\n</td>\n",
       "      <td>{'C': 10, 'gamma': 0.4, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(True, tfidf, True, SVM)</td>\n",
       "      <td>0.616293</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.54      0.65      0.59       475\\n    negative       0.70      0.77      0.73       766\\n     neutral       0.53      0.32      0.40       453\\n\\n   micro avg       0.62      0.62      0.62      1694\\n   macro avg       0.59      0.58      0.57      1694\\nweighted avg       0.61      0.62      0.60      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(True, tfidf, False, Naive)</td>\n",
       "      <td>0.587367</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.62      0.52      0.57       475\\n    negative       0.57      0.94      0.71       766\\n     neutral       0.93      0.06      0.10       453\\n\\n   micro avg       0.59      0.59      0.59      1694\\n   macro avg       0.71      0.51      0.46      1694\\nweighted avg       0.68      0.59      0.51      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(False, cv, False, SVM)</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.51      0.64      0.57       475\\n    negative       0.73      0.68      0.70       766\\n     neutral       0.44      0.38      0.41       453\\n\\n   micro avg       0.59      0.59      0.59      1694\\n   macro avg       0.56      0.57      0.56      1694\\nweighted avg       0.59      0.59      0.59      1694\\n</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(True, tfidf, True, Naive)</td>\n",
       "      <td>0.585596</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.62      0.52      0.57       475\\n    negative       0.57      0.94      0.71       766\\n     neutral       0.93      0.06      0.11       453\\n\\n   micro avg       0.59      0.59      0.59      1694\\n   macro avg       0.71      0.51      0.46      1694\\nweighted avg       0.68      0.59      0.51      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(False, boolean, False, SVM)</td>\n",
       "      <td>0.585006</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.50      0.63      0.56       475\\n    negative       0.73      0.67      0.70       766\\n     neutral       0.45      0.38      0.41       453\\n\\n   micro avg       0.59      0.59      0.59      1694\\n   macro avg       0.56      0.56      0.56      1694\\nweighted avg       0.59      0.59      0.58      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(False, cv, True, SVM)</td>\n",
       "      <td>0.582054</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.51      0.63      0.56       475\\n    negative       0.72      0.68      0.70       766\\n     neutral       0.44      0.37      0.40       453\\n\\n   micro avg       0.58      0.58      0.58      1694\\n   macro avg       0.56      0.56      0.55      1694\\nweighted avg       0.59      0.58      0.58      1694\\n</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(False, tfidf, True, Naive)</td>\n",
       "      <td>0.582054</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.70      0.48      0.57       475\\n    negative       0.55      0.97      0.70       766\\n     neutral       0.94      0.03      0.06       453\\n\\n   micro avg       0.58      0.58      0.58      1694\\n   macro avg       0.73      0.49      0.44      1694\\nweighted avg       0.69      0.58      0.49      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(False, tfidf, False, Naive)</td>\n",
       "      <td>0.579103</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.69      0.45      0.55       475\\n    negative       0.55      0.98      0.70       766\\n     neutral       0.94      0.04      0.07       453\\n\\n   micro avg       0.58      0.58      0.58      1694\\n   macro avg       0.73      0.49      0.44      1694\\nweighted avg       0.69      0.58      0.49      1694\\n</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(False, boolean, True, SVM)</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.49      0.64      0.56       475\\n    negative       0.72      0.67      0.70       766\\n     neutral       0.44      0.36      0.39       453\\n\\n   micro avg       0.58      0.58      0.58      1694\\n   macro avg       0.55      0.56      0.55      1694\\nweighted avg       0.58      0.58      0.58      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(True, cv, True, SVM)</td>\n",
       "      <td>0.570838</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.48      0.61      0.54       475\\n    negative       0.73      0.65      0.69       766\\n     neutral       0.44      0.40      0.42       453\\n\\n   micro avg       0.57      0.57      0.57      1694\\n   macro avg       0.55      0.55      0.55      1694\\nweighted avg       0.58      0.57      0.57      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(True, cv, False, SVM)</td>\n",
       "      <td>0.566116</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.48      0.60      0.54       475\\n    negative       0.72      0.65      0.68       766\\n     neutral       0.43      0.39      0.41       453\\n\\n   micro avg       0.57      0.57      0.57      1694\\n   macro avg       0.54      0.55      0.54      1694\\nweighted avg       0.58      0.57      0.57      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(True, boolean, False, SVM)</td>\n",
       "      <td>0.562574</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.48      0.62      0.54       475\\n    negative       0.71      0.63      0.67       766\\n     neutral       0.43      0.39      0.41       453\\n\\n   micro avg       0.56      0.56      0.56      1694\\n   macro avg       0.54      0.55      0.54      1694\\nweighted avg       0.57      0.56      0.56      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(True, boolean, True, SVM)</td>\n",
       "      <td>0.560213</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n    positive       0.48      0.60      0.53       475\\n    negative       0.71      0.64      0.67       766\\n     neutral       0.43      0.39      0.41       453\\n\\n   micro avg       0.56      0.56      0.56      1694\\n   macro avg       0.54      0.54      0.54      1694\\nweighted avg       0.57      0.56      0.56      1694\\n</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        parameters  accuracy  \\\n",
       "14       (False, cv, False, Naive)  0.643447   \n",
       "12        (False, cv, True, Naive)  0.637544   \n",
       "22  (False, boolean, False, Naive)  0.635773   \n",
       "20   (False, boolean, True, Naive)  0.631641   \n",
       "19      (False, tfidf, False, SVM)  0.629280   \n",
       "17       (False, tfidf, True, SVM)  0.626919   \n",
       "10   (True, boolean, False, Naive)  0.626328   \n",
       "2         (True, cv, False, Naive)  0.626328   \n",
       "8     (True, boolean, True, Naive)  0.623967   \n",
       "0          (True, cv, True, Naive)  0.620425   \n",
       "7        (True, tfidf, False, SVM)  0.619835   \n",
       "5         (True, tfidf, True, SVM)  0.616293   \n",
       "6      (True, tfidf, False, Naive)  0.587367   \n",
       "15         (False, cv, False, SVM)  0.586777   \n",
       "4       (True, tfidf, True, Naive)  0.585596   \n",
       "23    (False, boolean, False, SVM)  0.585006   \n",
       "13          (False, cv, True, SVM)  0.582054   \n",
       "16     (False, tfidf, True, Naive)  0.582054   \n",
       "18    (False, tfidf, False, Naive)  0.579103   \n",
       "21     (False, boolean, True, SVM)  0.578512   \n",
       "1            (True, cv, True, SVM)  0.570838   \n",
       "3           (True, cv, False, SVM)  0.566116   \n",
       "11     (True, boolean, False, SVM)  0.562574   \n",
       "9       (True, boolean, True, SVM)  0.560213   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                  summary  \\\n",
       "14                precision    recall  f1-score   support\\n\\n    positive       0.56      0.73      0.63       475\\n    negative       0.71      0.82      0.76       766\\n     neutral       0.62      0.26      0.36       453\\n\\n   micro avg       0.64      0.64      0.64      1694\\n   macro avg       0.63      0.60      0.59      1694\\nweighted avg       0.64      0.64      0.62      1694\\n   \n",
       "12                precision    recall  f1-score   support\\n\\n    positive       0.54      0.73      0.62       475\\n    negative       0.72      0.80      0.76       766\\n     neutral       0.60      0.26      0.36       453\\n\\n   micro avg       0.64      0.64      0.64      1694\\n   macro avg       0.62      0.60      0.58      1694\\nweighted avg       0.64      0.64      0.61      1694\\n   \n",
       "22                precision    recall  f1-score   support\\n\\n    positive       0.54      0.73      0.62       475\\n    negative       0.71      0.80      0.75       766\\n     neutral       0.63      0.25      0.35       453\\n\\n   micro avg       0.64      0.64      0.64      1694\\n   macro avg       0.62      0.60      0.58      1694\\nweighted avg       0.64      0.64      0.61      1694\\n   \n",
       "20                precision    recall  f1-score   support\\n\\n    positive       0.54      0.73      0.62       475\\n    negative       0.71      0.80      0.75       766\\n     neutral       0.61      0.24      0.34       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.62      0.59      0.57      1694\\nweighted avg       0.63      0.63      0.61      1694\\n   \n",
       "19                precision    recall  f1-score   support\\n\\n    positive       0.56      0.68      0.61       475\\n    negative       0.71      0.78      0.75       766\\n     neutral       0.53      0.31      0.39       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.60      0.59      0.58      1694\\nweighted avg       0.62      0.63      0.61      1694\\n   \n",
       "17                precision    recall  f1-score   support\\n\\n    positive       0.55      0.68      0.61       475\\n    negative       0.71      0.78      0.74       766\\n     neutral       0.53      0.31      0.39       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.60      0.59      0.58      1694\\nweighted avg       0.62      0.63      0.61      1694\\n   \n",
       "10                precision    recall  f1-score   support\\n\\n    positive       0.54      0.75      0.63       475\\n    negative       0.72      0.75      0.73       766\\n     neutral       0.56      0.28      0.37       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.61      0.60      0.58      1694\\nweighted avg       0.63      0.63      0.61      1694\\n   \n",
       "2                 precision    recall  f1-score   support\\n\\n    positive       0.54      0.75      0.63       475\\n    negative       0.72      0.75      0.73       766\\n     neutral       0.54      0.28      0.37       453\\n\\n   micro avg       0.63      0.63      0.63      1694\\n   macro avg       0.60      0.60      0.58      1694\\nweighted avg       0.62      0.63      0.61      1694\\n   \n",
       "8                 precision    recall  f1-score   support\\n\\n    positive       0.53      0.74      0.62       475\\n    negative       0.72      0.76      0.74       766\\n     neutral       0.56      0.28      0.37       453\\n\\n   micro avg       0.62      0.62      0.62      1694\\n   macro avg       0.60      0.59      0.58      1694\\nweighted avg       0.62      0.62      0.61      1694\\n   \n",
       "0                 precision    recall  f1-score   support\\n\\n    positive       0.54      0.74      0.63       475\\n    negative       0.71      0.75      0.73       766\\n     neutral       0.53      0.27      0.35       453\\n\\n   micro avg       0.62      0.62      0.62      1694\\n   macro avg       0.59      0.59      0.57      1694\\nweighted avg       0.61      0.62      0.60      1694\\n   \n",
       "7                 precision    recall  f1-score   support\\n\\n    positive       0.55      0.67      0.60       475\\n    negative       0.71      0.76      0.73       766\\n     neutral       0.51      0.34      0.41       453\\n\\n   micro avg       0.62      0.62      0.62      1694\\n   macro avg       0.59      0.59      0.58      1694\\nweighted avg       0.61      0.62      0.61      1694\\n   \n",
       "5                 precision    recall  f1-score   support\\n\\n    positive       0.54      0.65      0.59       475\\n    negative       0.70      0.77      0.73       766\\n     neutral       0.53      0.32      0.40       453\\n\\n   micro avg       0.62      0.62      0.62      1694\\n   macro avg       0.59      0.58      0.57      1694\\nweighted avg       0.61      0.62      0.60      1694\\n   \n",
       "6                 precision    recall  f1-score   support\\n\\n    positive       0.62      0.52      0.57       475\\n    negative       0.57      0.94      0.71       766\\n     neutral       0.93      0.06      0.10       453\\n\\n   micro avg       0.59      0.59      0.59      1694\\n   macro avg       0.71      0.51      0.46      1694\\nweighted avg       0.68      0.59      0.51      1694\\n   \n",
       "15                precision    recall  f1-score   support\\n\\n    positive       0.51      0.64      0.57       475\\n    negative       0.73      0.68      0.70       766\\n     neutral       0.44      0.38      0.41       453\\n\\n   micro avg       0.59      0.59      0.59      1694\\n   macro avg       0.56      0.57      0.56      1694\\nweighted avg       0.59      0.59      0.59      1694\\n   \n",
       "4                 precision    recall  f1-score   support\\n\\n    positive       0.62      0.52      0.57       475\\n    negative       0.57      0.94      0.71       766\\n     neutral       0.93      0.06      0.11       453\\n\\n   micro avg       0.59      0.59      0.59      1694\\n   macro avg       0.71      0.51      0.46      1694\\nweighted avg       0.68      0.59      0.51      1694\\n   \n",
       "23                precision    recall  f1-score   support\\n\\n    positive       0.50      0.63      0.56       475\\n    negative       0.73      0.67      0.70       766\\n     neutral       0.45      0.38      0.41       453\\n\\n   micro avg       0.59      0.59      0.59      1694\\n   macro avg       0.56      0.56      0.56      1694\\nweighted avg       0.59      0.59      0.58      1694\\n   \n",
       "13                precision    recall  f1-score   support\\n\\n    positive       0.51      0.63      0.56       475\\n    negative       0.72      0.68      0.70       766\\n     neutral       0.44      0.37      0.40       453\\n\\n   micro avg       0.58      0.58      0.58      1694\\n   macro avg       0.56      0.56      0.55      1694\\nweighted avg       0.59      0.58      0.58      1694\\n   \n",
       "16                precision    recall  f1-score   support\\n\\n    positive       0.70      0.48      0.57       475\\n    negative       0.55      0.97      0.70       766\\n     neutral       0.94      0.03      0.06       453\\n\\n   micro avg       0.58      0.58      0.58      1694\\n   macro avg       0.73      0.49      0.44      1694\\nweighted avg       0.69      0.58      0.49      1694\\n   \n",
       "18                precision    recall  f1-score   support\\n\\n    positive       0.69      0.45      0.55       475\\n    negative       0.55      0.98      0.70       766\\n     neutral       0.94      0.04      0.07       453\\n\\n   micro avg       0.58      0.58      0.58      1694\\n   macro avg       0.73      0.49      0.44      1694\\nweighted avg       0.69      0.58      0.49      1694\\n   \n",
       "21                precision    recall  f1-score   support\\n\\n    positive       0.49      0.64      0.56       475\\n    negative       0.72      0.67      0.70       766\\n     neutral       0.44      0.36      0.39       453\\n\\n   micro avg       0.58      0.58      0.58      1694\\n   macro avg       0.55      0.56      0.55      1694\\nweighted avg       0.58      0.58      0.58      1694\\n   \n",
       "1                 precision    recall  f1-score   support\\n\\n    positive       0.48      0.61      0.54       475\\n    negative       0.73      0.65      0.69       766\\n     neutral       0.44      0.40      0.42       453\\n\\n   micro avg       0.57      0.57      0.57      1694\\n   macro avg       0.55      0.55      0.55      1694\\nweighted avg       0.58      0.57      0.57      1694\\n   \n",
       "3                 precision    recall  f1-score   support\\n\\n    positive       0.48      0.60      0.54       475\\n    negative       0.72      0.65      0.68       766\\n     neutral       0.43      0.39      0.41       453\\n\\n   micro avg       0.57      0.57      0.57      1694\\n   macro avg       0.54      0.55      0.54      1694\\nweighted avg       0.58      0.57      0.57      1694\\n   \n",
       "11                precision    recall  f1-score   support\\n\\n    positive       0.48      0.62      0.54       475\\n    negative       0.71      0.63      0.67       766\\n     neutral       0.43      0.39      0.41       453\\n\\n   micro avg       0.56      0.56      0.56      1694\\n   macro avg       0.54      0.55      0.54      1694\\nweighted avg       0.57      0.56      0.56      1694\\n   \n",
       "9                 precision    recall  f1-score   support\\n\\n    positive       0.48      0.60      0.53       475\\n    negative       0.71      0.64      0.67       766\\n     neutral       0.43      0.39      0.41       453\\n\\n   micro avg       0.56      0.56      0.56      1694\\n   macro avg       0.54      0.54      0.54      1694\\nweighted avg       0.57      0.56      0.56      1694\\n   \n",
       "\n",
       "                                  model_details  \n",
       "14                                            -  \n",
       "12                                            -  \n",
       "22                                            -  \n",
       "20                                            -  \n",
       "19   {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "17   {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "10                                            -  \n",
       "2                                             -  \n",
       "8                                             -  \n",
       "0                                             -  \n",
       "7      {'C': 10, 'gamma': 0.4, 'kernel': 'rbf'}  \n",
       "5    {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "6                                             -  \n",
       "15  {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "4                                             -  \n",
       "23   {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "13  {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "16                                            -  \n",
       "18                                            -  \n",
       "21   {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "1    {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "3    {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "11   {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  \n",
       "9    {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = Executor()\n",
    "e.create_models()\n",
    "e.fit_models()\n",
    "e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e.summary().loc[...]['summary'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
